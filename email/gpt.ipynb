{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takes the content of an email as input and generates a short subject line summary using OpenAI's GPT-4 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative Proposal on Healthcare Analytics Solutions\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes email contents and provide a short subject line summary\"\n",
    "user_prompt = \"\"\"\n",
    "Dear Dr. Johnson,\n",
    "\n",
    "I hope this email finds you well. My name is Justine Okumu, and I am an AI Engineer at Innovate Analytics. I am reaching out to explore a potential collaboration between our teams on developing advanced analytics solutions for healthcare data.\n",
    "Your recent publication on predictive modeling in patient care greatly inspired our current project on improving hospital resource allocation. We believe your expertise could significantly enhance the project’s scope, and we would love to discuss possible synergies.\n",
    "If this aligns with your interests, I would appreciate the opportunity to set up a meeting at your earliest convenience. Please let me know your availability, and I’ll gladly arrange a time that works for you.\n",
    "Thank you for considering this collaboration. I look forward to your response.\n",
    "\n",
    "Best regards,\n",
    "Justine Okumu\n",
    "AI Engineer | Innovate Analytics\n",
    "okumujustine.com\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "def create_prompt_sms(role, content):\n",
    "    return {\n",
    "        'role': role,\n",
    "        'content': content\n",
    "    }\n",
    "messages = [\n",
    "    create_prompt_sms('system', system_prompt),\n",
    "    create_prompt_sms('user', user_prompt)\n",
    "] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = messages\n",
    ")\n",
    "\n",
    "# Step 4: print the result\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
